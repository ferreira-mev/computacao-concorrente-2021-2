% !TEX program = xelatex

\documentclass{article}

\input{personaldata.tex} % (so my full name and DRE won't be on GitHub)
\input{../out/f1_time.tex}
\input{../out/f1_acc.tex}
\input{../out/f2_time.tex}
\input{../out/f2_acc.tex}
\input{../out/f3_time.tex}
\input{../out/f3_acc.tex}
% (estava demorando mais pra colocar o pacote foreach pra funcionar
% com os inputs do que pra só copiar e colar isso :P)

\usepackage[brazil]{babel}
\usepackage{csquotes}
\usepackage{enumitem}
\usepackage{xurl}  % linebreaks at any character

\usepackage{graphicx}
\graphicspath{ {..} }

\usepackage{hyperref}

\hypersetup{
    colorlinks=true,
    citecolor=blue,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=blue
}

\urlstyle{same}

\usepackage{listings}

\lstset{
  basicstyle=\ttfamily,
  breaklines=true,
  breakatwhitespace=false
} 

\usepackage[style=numeric, sorting=nyt]{biblatex}
\addbibresource{EduardaFerreira-CompConc-trab-relatorio.bib}

\usepackage{amsmath, amsfonts}

\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}

\begin{document}

\begin{center}
  \begin{Large}
    \textbf{Trabalho de Implementação}
  \end{Large}

  \vspace{8pt}

  \begin{large}
    \textbf{Computação Concorrente (MAB-117) — 2021/2}
  \end{large}

  \vspace{8pt}

  \begin{Large}
    \textbf{Implementação paralela do método do trapézio para integração numérica}
  \end{Large}

  \vspace{12pt}

  \begin{large}
    \textbf{\fullname\textsuperscript{1}}  % as defined in personaldata.tex

    \vspace{5pt}

    \textsuperscript{1}Graduação em Matemática Aplicada, IM, UFRJ; DRE \DRE % as defined in personaldata.tex
  \end{large}

\end{center}

  \section{Descrição do problema} \label{descr}

  Dentre os temas sugeridos, chamou-me atenção a integração numérica, por se tratar de um assunto que eu já havia estudado no curso de Computação Científica I do prof.\ Bernardo Costa\cite{cci}. Trata-se do problema de, dadas uma função matemática e uma região de integração, calcular uma aproximação do valor da integral da função nessa região por meio de um algoritmo, sem a obtenção de uma primitiva da função em estudo. Para fins deste trabalho, restringi-me a funções reais de uma variável real, da forma $f: \R \to \R$, e intervalos reais de integração $[a, b] \in \R$, com $-\infty < a < b < \infty$.

  A integração numérica é de interesse sobretudo ao lidar com funções cujas primitivas sejam desconhecidas, bem como para possibilitar a incorporação de uma etapa de integração num programa computacional de forma mais simples e menos computacionalmente custosa do que com o uso de um sistema capaz de realizar integração simbólica.
  
  Na disciplina de CC I, fizemos tanto um estudo teórico/analítico de alguns algoritmos para aproximação numérica de integrais quanto uma implementação prática desses algoritmos, em sua forma sequencial, em linguagem Python; ambos incluíram o estudo dos erros de aproximação (analítico) e numérico. 
  
  Um dos métodos estudados foi o do trapézio, que recebe esse nome devido a sua interpretação geométrica. No caso de funções reais de uma variável real, sabe-se que a integral definida de $f$ em $[a, b]$ fornece a ``área com sinal'' sob o gráfico da função no intervalo de integração, i.e., a medida da área entre o eixo $x$ e o lugar geométrico dos pontos $(x, f(x))$, $a \leq x \leq b$, multiplicada por -1 nas regiões onde $f(x) < 0$, e novamente multiplicada por -1 se $b < a$. 
  
  No método do trapézio, particiona-se $[a, b]$ em $n \in \N \setminus \{0\}$ subintervalos $I_i = [x_i, x_{i+1}]$ e aproxima-se o valor da integral em cada subintervalo por
  \begin{equation} \label{trapterm}
    \frac{b-a}{n} \frac{f(x_i) + f(x_{i+1})}{2} =: h \frac{f(x_i) + f(x_{i+1})}{2},
  \end{equation}\noindent
  onde $h$ é definido como o comprimento de cada subintervalo. Quando $f(x) > 0$ para todo $x \in I_i$, isso equivale à área de um trapézio de vértices $(x_i, 0)$, $(x_{i+1}, 0)$, $(x_i, f(x_i))$ e $(x_{i+1}, f(x_{i+1}))$. % imagem?

  Desse modo, dados $f: \R \to \R$ e $[a, b] \in \R$ e fixado um valor de $n \in \N \setminus \{0\}$, o método do trapézio nos fornece a aproximação
  \begin{equation} \label{trapformula}
    \int_a^b f(x) dx \approx \sum_{i=0}^{n-1} \frac{b-a}{n} \frac{f(x_i) + f(x_{i+1})}{2} = h \sum_{i=0}^{n-1} \frac{f(x_i) + f(x_{i+1})}{2}.
  \end{equation}

  Conforme seria intuitivamente esperado, a precisão do método será tanto maior quanto for pequeno o valor de $h$. Sob a suposição que de $f$ seja duas vezes diferenciável, demonstra-se\cite{cci} que o erro total de aproximação -- aquele que é analiticamente esperado devido ao próprio método, independentemente da precisão da representação computacional com que se trabalhe -- é da ordem de $h^2$; mais especificamente, ele é dado por
  \begin{equation} \label{traperr}
    e^T_h := \frac{f'(b)-f'(a)}{12} h^2 + o(h^2),
  \end{equation} \noindent
  onde por $o(h^2)$ denota-se termos que, divididos por $h^2$, tendem a 0 quando $h \to 0$. (Vale ressaltar que, como estar-se-ia sempre trabalhando com $h \ll 1$, o que é relevante é o comportamento do erro quando $h$ é próximo de 0, e a magnitude dos termos com fatores $h^k$ será menor para $k$ maior.)

  Observando \eqref{trapformula}, é possível constatar que esse algoritmo pode ser facilmente tornado paralelo, dado que os termos calculados para cada índice $i$ são independentes dos demais (exceto na medida em que, para $i < n - 1$, os valores de $f'(x_{i+1})$ reparecem como $f'(x_i)$ no termo seguinte, de modo a beneficiarem-se de alguma forma de armazenamento do valor obtido no termo anterior, numa lógica análoga à de um cache simples; entretanto, isso é uma possível otimização, e não uma dependência estrita).
  
  Uma vez que, numa implementação sequencial, os $n$ termos de \eqref{trapformula} seriam calculados um após o outro, pode-se esperar um ganho de perfomance ao dividi-los entre múltiplas threads de execução paralela num processador multicore, sobretudo se essa divisão for feita de modo a reduzir a quantidade de cálculos de $f'(x_i)$, alocando blocos de subintervalos consecutivos para a mesma thread.

  \section{Projeto e implementação da solução concorrente}

  Como no caso de outros algoritmos paralelos estudados na disciplina, o cálculo dos valores de \eqref{trapterm} para diferentes subintervalos pode ser distribuído entre as threads de diversas formas, dentre as quais destacam-se mais imediatamente as divisões ``em listras'' ou ``em blocos''. Por ``em listras'', quero dizer que, se há $t$ threads, o subintervalo de índice 0 caberia à thread de índice 0, $I_1$ à thread 1, ..., $I_{t - 1}$ à $t-1$, $I_{t}$ à thread 0 outra vez, $I_{t + 1}$ à $1$, e assim sucessivamente; ou seja, o subintervalo $i$ seria alocado para a thread $i \% t$.

  Já a divisão que chamo de ``em blocos'' corresponderia a subdividir os $n$ subintervalos em $t$ grupos, com os $t - 1$ primeiros contendo $m := \lfloor n/t \rfloor$ subintervalos, com índices $ k m \leq i < (k+1) m$ para o grupo $k$, $0 \leq k \leq t-2$; e o último contendo os subintervalos de índices $(t-1)m \leq k \leq n - 1$. (Conforme discutido em aula, essa solução não garante um balanceamento perfeito se a quantidade $n$ de subintervalos não é divisível pela quantidade $t$ de threads; contudo, nesse caso, esse balanceamento é impossível, e essa é uma divisão simples que se aproxima bastante de uma distribuição equilibrada para $n \gg t$.)

  Optei por esta última divisão para reduzir a quantidade de operações efetuadas alocando subintervalos com índices consecutivos para a mesma thread, assim permitindo que os valores de $x_{i+1}$ e $f'(x_{i+1})$ computados numa iteração sejam mantidos na memória e reproveitados como $x_i$ e $f'(x_i)$ na iteração seguinte (vide seção \ref{descr}).

  No mais, os extremos do intervalo $[a, b]$ e as funções de C que implementam as funções matemáticas a integrar foram representadas por variáveis globais, de modo a serem facilmente acessíveis por todas as threads e pela implementação sequencial usada para comparação (vide \ref{tests}). Incluí também o número $n$ de subintervalos como parâmetro.
  
  Os parâmetros necessários para a tarefa executada pelas threads são passados na forma de um \texttt{struct}. Como o trabalho previa uma etapa de testes e outra de avaliação de desempenho (cf.\ \ref{tests} e \ref{perf}), as funções já foram implementadas com essas finalidades em mente; dessa forma, além da identificação da thread, da quantidade total de threads e do número de subintervalos (estes dois últimos, para determinar quais subintervalos a thread deve considerar), é passado a cada thread o índice para acesso da função a integrar no array de casos de teste.

  Não variei os valores de $a$ e $b$ ao realizar as verificações e medições, pois o programa já estava gerando uma grande quantidade de medidas para as diferentes funções e números de threads e de subintervalos. Visto que a avaliação a ser feita era apenas do tempo de execução e não, por exemplo, da precisão do método sob diferentes condições, julguei que não seria necessário gerar mais tabelas para diferentes $[a, b]$, como o número de operações é afetado apenas pela quantidade de subintervalos e não por \emph{quais} eles são. Escolhi o intervalo de integração $[1, 11]$ por pertencer ao domínio de todas as funções em estudo e por não seus elementos não gerarem problemas de under ou overflow aritmético ao serem representados como double em C e passarem pelas operações envolvidas nos testes (que vão desde a divisão por $10^7$ até a elevação à sexta potência). Assim, como o intervalo manteve-se inalterado, seus extremos foram representados por variáveis globais acessadas diretamente pelas threads ou pela função sequencial, e não por parâmetros.

  Os parâmetros da função sequencial são o índice da função a integrar e a quantidade $n$ de subintervalos.

  O somatório dos valores de \eqref{trapterm} computados por cada thread é somado e retornado à thread principal, que agrega essas somas parciais num somatório total correspondente a \eqref{trapformula}.

  Não incluí verificações de cunho matemático, como o pertencimento do intervalo $[a, b]$ ao domínio de $f$, que seriam de implementação complexa e fugiriam ao escopo do trabalho.

  Para reduzir a quantidade de linhas do arquivo contendo o programa principal, com o algoritmo do método de trapézio e a execução dos testes, movi as funções de teste para o arquivo separado \texttt{testfunctions.c}, e algumas funções auxiliares para \texttt{helperfunctions.c}.

  \section{Casos de teste} \label{tests}

  A corretude da implementação concorrente do método do trapézio foi verificada por meio de duas comparações:
  
  \begin{enumerate}[label=(\roman*)]
    \item com uma versão sequencial do mesmo algoritmo, implementada no mesmo programa em C; \label{seq}
    
    \item com o resultado ``analítico'' (também calculado numericamente em C, porém a partir das primitivas simbólicas das funções em estudo), acrescido do primeiro termo do erro de aproximação \eqref{traperr}. (Isso pode causar estranhamento à primeira vista, porém, nos casos em que $f'$ é facilmente obtenível -- o que nem sempre se aplica aos casos em que se precisa recorrer à integração numérica --, como o erro analítico de aproximação é conhecido, uma quantidade finita de seus termos pode ser subtraída da saída do método do trapézio para gerar um resultado mais preciso. Nesse caso, restariam apenas o erro numérico e os termos de ordem maior do erro de aproximação.) \label{symb}
  \end{enumerate}
  
  Para possibilitar \ref{symb}, foram escolhidas três funções de fácil integração, bem como de fácil derivação (para o cálculo do erro de aproximação \eqref{traperr}):
  \begin{equation} \label{f1}
   f_1(x) = 4x^5 + x^2 - 3x - 5
  \end{equation}
  \begin{equation} \label{f2}
    f_2(x) = \frac{1}{x}
  \end{equation}
  \begin{equation} \label{f3}
    f_3(x) = \cos{2x}
  \end{equation}

  Suas primitivas, com constante de integração zero, são
  \begin{equation*}
    F_1(x) = \frac{2}{3} x^6 + \frac{1}{3} x^3 - \frac{3}{2} x^2 - 5x
  \end{equation*}
  \begin{equation*}
    F_2(x) = \log{x} \qquad F_3(x) = \sin{x}\cos{x},
  \end{equation*} \noindent
  e suas derivadas são
  \begin{equation*}
    f'_1(x) = 20x^4 + 2x - 3
  \end{equation*}
  \begin{equation*}
    f'_2(x) = -\frac{1}{x^2} \qquad f'_3(x) = -2\sin{2x}.
  \end{equation*}

  A comparação entre números de ponto flutuante foi feita conforme \cite{float}, adotando um valor de $\delta = 10^{-8}$ como critério de proximidade relativa entre os resultados. Não houve um procedimento rigoroso para determinação do valor ideal de $\delta$, apenas uma consideração do que seria um valor ``razoável'' para verificar a corretude do algoritmo, considerando as precisões do método e da máquina e a experiência de Computação Científica I. 
  
  Tanto o teste \ref{seq} quanto o \ref{symb} foram executados com sucesso para todas as funções acima, para todas as combinações de números de threads $2k$, $1 \leq k \leq 5$, e números de subintervalos $10^m$, $3 \leq k \leq 7$. Observo que a variação do número $n$ de subintervalos é análoga, para este problema, à variação da dimensão dos dados de entrada, cuja necessidade na testagem havia sido apontada nas instruções do trabalho, pois é o valor de $n$ que determina o número de operações a serem realizadas.

  \section{Avaliação de desempenho} \label{perf}

  As mesmas funções $f_1$, $f_2$ e $f_3$ (\eqref{f1}, \eqref{f2} e \eqref{f3}) foram usadas para avaliação de desempenho, bem como o intervalo $[1, 11]$, os números de threads $2k$, $1 \leq k \leq 5$, e os números de subintervalos $10^m$, $3 \leq k \leq 7$, em todas as suas combinações possíveis.

  Para cada combinação, o tempo de execução das implementações sequencial e concorrente, incluindo a inicialização das threads e agregação de suas saídas no cômputo final, foi medido cinco vezes, usando a função \texttt{GET\_TIME} de \texttt{timer.h} (arquivo fornecido no laboratório 2), configurada para retornar valores em segundos. (A execução sequencial não foi repetida para diferentes valores do número de threads, já que não é afetada por esse valor.) Foi considerada a média dos valores aferidos. A aceleração foi calculada como a razão entre os tempos de execução médios sequencial e concorrente, ou seja:
  \begin{equation} \label{acc}
    \alpha = \frac{\bar{t}_{\text{seq}}}{\bar{t}_{\text{conc}}} = \frac{\frac{1}{5} \sum_{i=0}^4 t_{\text{seq}_i}}{\frac{1}{5} \sum_{i=0}^4 t_{\text{conc}_i}}.
  \end{equation}

  As execuções e medições foram feitas numa máquina com 4 cores físicos e 8 lógicos, rodando o sistema operacional Fedora 35 Workstation. Parte da saída do comando \texttt{lscpu} é reproduzida abaixo:

\begin{lstlisting}
Architecture:            x86_64
  CPU op-mode(s):        32-bit, 64-bit
    ...
CPU(s):                  8
  On-line CPU(s) list:   0-7
Vendor ID:               GenuineIntel
  Model name:            Intel(R) Core(TM) i7-7700HQ CPU @ 2.80GHz
    CPU family:          6
    Model:               158
    Thread(s) per core:  2
    Core(s) per socket:  4
    Socket(s):           1
    Stepping:            9
    CPU max MHz:         3800.0000
    CPU min MHz:         800.0000
    ...
\end{lstlisting}

  Uma observação: Desta vez, diferentemente do que havia comentado em um laboratório anterior, eu optei por \emph{não} tentar deixar as funções sequencial e concorrente o mais semelhantes o possível, no tocante a argumentos etc. Tomei essa decisão porque considerei que, no caso de uma implementação apenas sequencial, não haveria nenhum motivo para, por exemplo, usar \texttt{structs} ou determinadas variáveis globais em lugar de múltiplos argumentos. Como essas escolhas de implementação são forçadas pela concorrência, achei 
  que faria sentido medir qualquer (des)vantagem introduzida por elas 
  em termos de tempo de execução, para me aproximar melhor de uma 
  observação real das vantagens ``líquidas''\ oferecidas pela concorrência, descontados seus ``custos''.

  Os resultados estão expostos nas tabelas de \ref{f1t} a \ref{f3a}, disponíveis ao final do documento. Em todas elas, os valores nos cabeçalhos das colunas são os números de threads, e $n$ é o número de subintervalos em que foi dividido o intervalo de integração $[1, 11]$. Nas tabelas com medidas de tempo, a coluna ``seq.'' registra o tempo médio de execução do algoritmo sequencial. Os valores foram arredondados após a terceira casa decimal.

  \section{Discussão} \label{disc}

  Algo que que se pode notar é a diferença entre os tempos absolutos de execução entre as diferentes funções. Minha hipótese seria de que isso se relaciona com a quantidade de operações realizada para cálculo de $f_i(x)$ para cada $1 \leq i \leq 3$. A função $f_1$ \eqref{f1} é um polinômio, e a computação de seus valores envolve diversas multiplicações e adições, o que talvez justifique o porquê de sua execução (tabela \ref{f1t}) ser bem mais lenta do que o que ocorre com $f_2$ \eqref{f2} (tabela \ref{f2t}). Talvez o fato de $f_3$ \eqref{f3} ser intermediária entre as duas (tabela \eqref{f3t}) deva-se à forma como a função cosseno é implementada internamente -- talvez com uma aproximação por séries de Taylor, por exemplo, que também são funções polinomiais. Isso não é diretamente relacionado à concorrência em si, mas estou mencionando esse fato por poder estar relacionado às diferenças entre as acelerações aferidas para cada função.

  Ainda sobre a questão do tempo absoluto, conforme o esperado, esse tempo aumenta com $n$ para todas as funções, já que um aumento na quantidade de subintervalos acarreta numa maior quantidade de pontos onde calcular o valor da função e mais termos a somar.

  De relevância mais direta para a avaliação da paralelização, constata-se, para todas as funções, um ganho de velocidade com a paralelização, a partir de alguma combinação de valores de $n$ e números de threads, que chega a ser bastante expressivo em alguns casos, tendo resultado em tempos de execução mais de quatro vezes menores.

  Na maioria dos casos, o uso de uma única thread leva a uma execução mais lenta, devido ao overhead introduzido por sua criação e `1 ``sincronização''. Curiosamente, vemos na tabela \ref{f1a} que, apenas no caso da função $f_1$, houve um ganho muito pequeno de velocidade com o uso de uma única thread para $n$ a partir de $10^5$. Acredito que estejamos diante de algum ruído introduzido por diferenças pontuais entre os algoritmos paralelo e sequencial. (Sobre isso, ver o comentário próximo ao final da seção \ref{perf}.)
  
  Mais simples de explicar é a diminuição geral dessa desaceleração com o crescimento de $n$, pois, com mais operações, as etapas associadas à criação da única thread representam uma parcela menor do tempo total de processamento e os algoritmos sequencial e ``concorrente monothread'' se aproximam.

  Relacionado a isso, vê-se que, em todos os casos, a introdução da concorrência -- verdadeira, com duas ou mais threads -- tampouco foi vantajosa para $n$ muito pequeno. Provavelmente, o que ocorre é que, também nesses casos, como a quantidade de operações a ser realizada não é alta, o overhead da paralelização representa uma parcela significativa do tempo efetivo de processamento, de modo a não ser vantajoso.

  Para todas as funções, ao menos para $n \geq 10^5$, a paralelização torna-se vantajosa -- em geral, mais quanto mais cresce $n$ e reduz-se a fração do tempo de processamento representada pelas etapas adicionais introduzidas pela concorrência. Aqui, também, apenas no caso de $f_1$ o comportamento foi um pouco diferente, tendo havido uma aceleração menor quando $n = 10^7$ do que para $n = 10^6$. (Não consegui pensar numa possível justificativa para esse fato até o momento.)

  % aumento com t não foi tão direto, 6 às vezes é menor que 4 (entra no hyperthreading s/ aproveitar ao máximo?)
  % de 8 p/ 10 na maioria dos casos tb caiu um pouco, porque está passando p/ duas threads que já "não existem", nem virtualmente

  \section{Referências bibliográficas \protect\footnote{Era o título indicado para a sessão nas especificações do trabalho, mas,  rigor, foram usadas apenas referências cibernéticas!}} \label{bibl}

  \printbibliography[heading=none]

  \newpage

  \begin{table}
    \centering
    \timefA
    \end{tabular}
    \caption{Tempo de execução, em milissegundos, para a função $f_1$ \eqref{f1}.}
    \label{f1t}
  \end{table}

  \begin{table}
    \centering
    \accfA
    \end{tabular}
    \caption{Aceleração \eqref{acc} obtida para a função $f_1$ \eqref{f1}. }
    \label{f1a}
  \end{table}

  \begin{table}
    \centering
    \timefB
    \end{tabular}
    \caption{Tempo de execução, em milissegundos, para a função $f_2$ \eqref{f2}.}
    \label{f2t}
  \end{table}

  \begin{table}
    \centering
    \accfB
    \end{tabular}
    \caption{Aceleração \eqref{acc} obtida para a função $f_2$ \eqref{f2}. }
    \label{f2a}
  \end{table}

  \begin{table}
    \centering
    \timefC 
    \end{tabular}
    \caption{Tempo de execução, em milissegundos, para a função $f_3$ \eqref{f3}.}
    \label{f3t}
  \end{table}

  \begin{table}
    \centering
    \accfC
    \end{tabular}
    \caption{Aceleração \eqref{acc} obtida para a função $f_3$ \eqref{f3}. }
    \label{f3a}
  \end{table}

\end{document}